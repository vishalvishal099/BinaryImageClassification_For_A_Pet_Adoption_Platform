# üéØ MLOps Pipeline - Project Status

**Date:** February 21, 2026  
**Repository:** BinaryImageClassification_For_A_Pet_Adoption_Platform  
**Status:** ‚úÖ **Production Ready ‚Äî Full GitOps Stack Running**

---

## ‚úÖ **COMPLETED COMPONENTS**

### 1. Model Development & Training
- ‚úÖ **Dataset**: ~25,000 images (Cats vs Dogs)
- ‚úÖ **Model Architecture**: SimpleCNN
- ‚úÖ **Training**: 20 epochs completed
- ‚úÖ **Performance Metrics**:
  - Test Accuracy: **92.01%**
  - Precision: 95.42%
  - Recall: 88.25%
  - F1 Score: 91.69%
- ‚úÖ **Model Artifact**: `models/best_model.pt` (4.9MB)

### 2. Experiment Tracking
- ‚úÖ **MLflow**: Fully configured and operational on port **5001**
- ‚úÖ **Experiments Logged**: All training metrics, parameters, artifacts
- ‚úÖ **Artifacts in MLflow**: `best_model.pt`, `loss_curves.png`, `confusion_matrix.npy`
- ‚úÖ **Model Registry**: Model registered as `CatsDogsClassifier` ‚Üí **Production** stage
- ‚úÖ **Dagshub MLflow Remote**: https://dagshub.com/vishalvishal099/BinaryImageClassification_For_A_Pet_Adoption_Platform.mlflow
- ‚úÖ **Access**: `mlflow server --host 0.0.0.0 --port 5001 --backend-store-uri sqlite:///mlflow.db`

### 3. Code Quality & Testing
- ‚úÖ **Unit Tests**: 35/35 tests passing
- ‚úÖ **Test Coverage**: Preprocessing, inference, data loading
- ‚úÖ **Linting**: Black, isort, flake8, mypy configured
- ‚úÖ **Run Tests**: `pytest tests/ -v`

### 4. Data Pipeline
- ‚úÖ **Data Download**: Kaggle dataset via kagglehub
- ‚úÖ **Preprocessing**: Image resizing, normalization, augmentation
- ‚úÖ **Data Splits**: 80% train, 10% val, 10% test
- ‚úÖ **DVC**: Configured for data versioning (`dvc.yaml` defines preprocess ‚Üí train ‚Üí evaluate pipeline)
- ‚úÖ **Dagshub DVC Remote**: `https://dagshub.com/vishalvishal099/BinaryImageClassification_For_A_Pet_Adoption_Platform.dvc`
- ‚úÖ **Pull data**: `dvc pull` (authenticates via Dagshub token)

### 5. Inference Service
- ‚úÖ **FastAPI Application**: Fully functional
- ‚úÖ **Endpoints**:
  - `/health` - Health check
  - `/predict` - Image classification
  - `/metrics` - Prometheus metrics
- ‚úÖ **Run Locally**: `MODEL_PATH=models/best_model.pt uvicorn src.inference.app:app --port 8000`

### 6. CI/CD Pipeline
- ‚úÖ **GitHub Actions CI** (`.github/workflows/ci.yml`):
  - Lint code
  - Run tests
  - Build Docker image
  - Push to GitHub Container Registry (`ghcr.io`)
- ‚úÖ **GitHub Actions CD** (`.github/workflows/cd.yml`) ‚Äî **GitOps flow**:
  - **Job 1 ‚Äî `update-manifest`**: Updates image tag in `k8s/local/deployment.yaml` and commits `[skip ci]` back to `main`
  - **Job 2 ‚Äî `smoke-tests`**: Runs post-deploy health checks
  - **Job 3 ‚Äî `notify`**: Reports pipeline status
- ‚úÖ **ArgoCD** auto-detects manifest change and syncs deployment to Minikube (no manual `kubectl apply` needed)

### 7. Kubernetes Deployment
- ‚úÖ **Manifests Created**:
  - `k8s/namespace.yaml`
  - `k8s/local/deployment.yaml` (image tag auto-updated by CD pipeline)
  - `k8s/service.yaml`
  - `k8s/hpa.yaml` (Horizontal Pod Autoscaler)
  - `k8s/configmap.yaml`
  - `k8s/argocd-application.yaml`
- ‚úÖ **ArgoCD Application**: `cats-dogs-classifier` ‚Äî **Synced + Healthy**
  - UI: `https://localhost:9443` (admin / see `.env`)
  - Watches `k8s/local/` on `main` branch; auto-syncs on every manifest change

### 8. Containerization
- ‚úÖ **Dockerfile**: Multi-stage build optimized
- ‚úÖ **docker-compose.yml**: Full stack (app + MLflow + Prometheus + Grafana)
- ‚ö†Ô∏è **Local Docker**: Not installed (not required for cloud deployment)

### 9. Monitoring & Observability
- ‚úÖ **Prometheus**: Running on port **9090** (Podman container), scraping metrics from ports 8081 and 8000
  - URL: `http://localhost:9090/graph`
- ‚úÖ **Grafana**: Running on port **3000** (Homebrew service)
  - Dashboard: `http://localhost:3000/d/pet-adoption-ml-v2`
- ‚úÖ **Metrics Server**: `scripts/push_metrics.py` on port **8081** ‚Äî 31 metric families, 60+ time series (API, latency, predictions, model performance, errors, system, batch, data pipeline, business)
- ‚úÖ **MLflow**: Experiment tracking + model registry on port **5001**
  - URL: `http://localhost:5001`
- ‚úÖ **Structured Logging**: Using structlog
- ‚úÖ **Metrics Endpoint**: FastAPI `/metrics` with request counts, latencies

### 10. Documentation
- ‚úÖ **README.md**: Complete project overview
- ‚úÖ **DOCUMENTATION.md**: Detailed technical documentation
- ‚úÖ **Code Comments**: Comprehensive inline documentation

---

## üöÄ **DEPLOYMENT OPTIONS**

### Option 1: GitHub Actions (Recommended)
When you push code to GitHub, the CI/CD pipeline automatically:
1. Builds Docker image in GitHub's cloud
2. Runs all tests
3. Pushes image to ghcr.io
4. Can deploy to Kubernetes cluster

**Required Setup:**
- Add GitHub Secret: `GHCR_TOKEN` (GitHub Personal Access Token)
- Optional: Add `KUBECONFIG` for automated K8s deployment

### Option 2: Run Locally Without Docker
```bash
# Activate virtual environment
source venv/bin/activate

# Start MLflow tracking server (port 5001)
mlflow server --host 0.0.0.0 --port 5001 --backend-store-uri sqlite:///mlflow.db &

# Start Inference Service
MODEL_PATH=models/best_model.pt uvicorn src.inference.app:app --port 8000

# Run DVC pipeline (pull data from Dagshub + run stages)
dvc pull
dvc repro

# Run Tests
pytest tests/ -v
```

### Option 3: Cloud Deployment
Deploy directly to:
- **Azure Kubernetes Service (AKS)**
- **Amazon EKS**
- **Google Kubernetes Engine (GKE)**

Using the manifests in `k8s/` directory.

---

## üìã **WHAT'S NOT REQUIRED LOCALLY**

### ‚ùå Docker Desktop
- **Not needed** for local development
- **Not needed** for GitHub Actions CI/CD
- GitHub runners build Docker images in the cloud
- You can develop, test, and train models without Docker

### ‚ùå Local Kubernetes
- **Not needed** unless you want to test K8s manifests locally
- Use cloud Kubernetes (AKS, EKS, GKE) for production

---

## üéì **NEXT STEPS (Optional)**

### If You Want to Deploy:

1. **Set up GitHub Secrets**:
   ```
   GHCR_TOKEN - For container registry access
   ```

2. **Push to GitHub** (already done):
   ```bash
   git push origin main
   ```

3. **GitHub Actions will automatically**:
   - Build Docker image
   - Run tests
   - Push to ghcr.io

4. **For Kubernetes Deployment**:
   - Set up a K8s cluster (AKS/EKS/GKE)
   - Apply manifests: `kubectl apply -f k8s/`
   - Or use ArgoCD for GitOps

---

## ‚ú® **PROJECT HIGHLIGHTS**

- ‚úÖ **End-to-End MLOps Pipeline**: Complete from data to deployment
- ‚úÖ **High Accuracy**: 92% on test set
- ‚úÖ **Production-Ready Code**: Tested, linted, documented
- ‚úÖ **Cloud-Native**: Containerized, K8s-ready, full GitOps with ArgoCD
- ‚úÖ **Monitoring**: Prometheus (9090) + Grafana (3000) + 31 metric families
- ‚úÖ **CI/CD**: GitHub Actions CI + GitOps CD (manifest update ‚Üí ArgoCD auto-sync)
- ‚úÖ **Data Versioning**: DVC with Dagshub remote
- ‚úÖ **Experiment Tracking**: MLflow (5001) + Dagshub MLflow remote
- ‚úÖ **Works Without Local Docker**: Development and testing fully functional

---

## üìû **Quick Commands Reference**

```bash
# Train model
python src/training/train.py --config configs/train_config.yaml

# Run DVC pipeline (pull data + run stages via Dagshub remote)
dvc pull
dvc repro

# Run tests
pytest tests/ -v

# Start MLflow tracking server
mlflow server --host 0.0.0.0 --port 5001 --backend-store-uri sqlite:///mlflow.db

# Start inference service
MODEL_PATH=models/best_model.pt uvicorn src.inference.app:app --port 8000

# Start metrics server (Prometheus scrape target on :8081)
python scripts/push_metrics.py &

# Check ArgoCD app status
argocd app get cats-dogs-classifier

# Test inference
curl -X POST http://localhost:8000/predict \
  -F "file=@path/to/image.jpg"
```

### üîó Service URLs
| Service | URL |
|---------|-----|
| MLflow | http://localhost:5001 |
| FastAPI | http://localhost:8000 |
| Prometheus | http://localhost:9090/graph |
| Grafana | http://localhost:3000/d/pet-adoption-ml-v2 |
| ArgoCD | https://localhost:9443 |
| Metrics | http://localhost:8081/metrics |
| Dagshub | https://dagshub.com/vishalvishal099/BinaryImageClassification_For_A_Pet_Adoption_Platform |

---

**üéâ Congratulations! Your MLOps pipeline is complete and production-ready!**

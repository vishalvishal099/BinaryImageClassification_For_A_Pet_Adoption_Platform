{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0200fc6d",
   "metadata": {},
   "source": [
    "# Cats vs Dogs Classification - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides exploratory data analysis for the Cats vs Dogs classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b373bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4d465",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64659563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "RAW_DATA_DIR = project_root / 'data' / 'raw'\n",
    "PROCESSED_DATA_DIR = project_root / 'data' / 'processed'\n",
    "\n",
    "# Check if data directories exist\n",
    "print(f\"Raw data exists: {RAW_DATA_DIR.exists()}\")\n",
    "print(f\"Processed data exists: {PROCESSED_DATA_DIR.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(data_dir: Path) -> dict:\n",
    "    \"\"\"Count images in each class directory.\"\"\"\n",
    "    counts = {}\n",
    "    \n",
    "    if not data_dir.exists():\n",
    "        return counts\n",
    "    \n",
    "    for class_dir in data_dir.iterdir():\n",
    "        if class_dir.is_dir():\n",
    "            image_count = len([f for f in class_dir.iterdir() \n",
    "                              if f.suffix.lower() in {'.jpg', '.jpeg', '.png'}])\n",
    "            counts[class_dir.name] = image_count\n",
    "    \n",
    "    return counts\n",
    "\n",
    "# Count raw data\n",
    "if RAW_DATA_DIR.exists():\n",
    "    raw_counts = count_images(RAW_DATA_DIR)\n",
    "    print(\"Raw data counts:\")\n",
    "    for class_name, count in raw_counts.items():\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "    print(f\"  Total: {sum(raw_counts.values())} images\")\n",
    "else:\n",
    "    print(\"Raw data not found. Please download the dataset first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f54f20",
   "metadata": {},
   "source": [
    "## 2. Sample Images Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdccb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(data_dir: Path, n_samples: int = 8):\n",
    "    \"\"\"Visualize sample images from each class.\"\"\"\n",
    "    if not data_dir.exists():\n",
    "        print(\"Data directory not found.\")\n",
    "        return\n",
    "    \n",
    "    classes = [d for d in data_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(classes), n_samples, figsize=(16, 4*len(classes)))\n",
    "    \n",
    "    for i, class_dir in enumerate(classes):\n",
    "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "        samples = random.sample(images, min(n_samples, len(images)))\n",
    "        \n",
    "        for j, img_path in enumerate(samples):\n",
    "            img = Image.open(img_path)\n",
    "            ax = axes[i, j] if len(classes) > 1 else axes[j]\n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "            if j == 0:\n",
    "                ax.set_title(class_dir.name, fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize raw data samples\n",
    "if RAW_DATA_DIR.exists():\n",
    "    print(\"Sample images from raw dataset:\")\n",
    "    visualize_samples(RAW_DATA_DIR, n_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834db54c",
   "metadata": {},
   "source": [
    "## 3. Image Size Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_sizes(data_dir: Path, max_samples: int = 500):\n",
    "    \"\"\"Analyze image size distribution.\"\"\"\n",
    "    if not data_dir.exists():\n",
    "        print(\"Data directory not found.\")\n",
    "        return None, None\n",
    "    \n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    image_files = list(data_dir.rglob('*.jpg')) + list(data_dir.rglob('*.jpeg')) + list(data_dir.rglob('*.png'))\n",
    "    samples = random.sample(image_files, min(max_samples, len(image_files)))\n",
    "    \n",
    "    for img_path in samples:\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                widths.append(img.size[0])\n",
    "                heights.append(img.size[1])\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    return np.array(widths), np.array(heights)\n",
    "\n",
    "if RAW_DATA_DIR.exists():\n",
    "    widths, heights = analyze_image_sizes(RAW_DATA_DIR)\n",
    "    \n",
    "    if widths is not None:\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        # Width distribution\n",
    "        axes[0].hist(widths, bins=30, edgecolor='black', alpha=0.7)\n",
    "        axes[0].set_xlabel('Width (pixels)')\n",
    "        axes[0].set_ylabel('Count')\n",
    "        axes[0].set_title('Image Width Distribution')\n",
    "        axes[0].axvline(np.mean(widths), color='red', linestyle='--', label=f'Mean: {np.mean(widths):.0f}')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Height distribution\n",
    "        axes[1].hist(heights, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "        axes[1].set_xlabel('Height (pixels)')\n",
    "        axes[1].set_ylabel('Count')\n",
    "        axes[1].set_title('Image Height Distribution')\n",
    "        axes[1].axvline(np.mean(heights), color='red', linestyle='--', label=f'Mean: {np.mean(heights):.0f}')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        # Aspect ratio\n",
    "        aspect_ratios = widths / heights\n",
    "        axes[2].hist(aspect_ratios, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "        axes[2].set_xlabel('Aspect Ratio (W/H)')\n",
    "        axes[2].set_ylabel('Count')\n",
    "        axes[2].set_title('Aspect Ratio Distribution')\n",
    "        axes[2].axvline(1.0, color='red', linestyle='--', label='Square')\n",
    "        axes[2].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nImage Size Statistics:\")\n",
    "        print(f\"  Width - Min: {widths.min()}, Max: {widths.max()}, Mean: {widths.mean():.0f}\")\n",
    "        print(f\"  Height - Min: {heights.min()}, Max: {heights.max()}, Mean: {heights.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb73d72",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1a236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocess import load_and_resize_image, get_train_transforms, get_val_transforms\n",
    "import albumentations as A\n",
    "\n",
    "# Demonstrate preprocessing\n",
    "def show_preprocessing_pipeline(image_path: str):\n",
    "    \"\"\"Show preprocessing steps.\"\"\"\n",
    "    # Load original\n",
    "    original = Image.open(image_path)\n",
    "    \n",
    "    # Load and resize\n",
    "    resized = load_and_resize_image(image_path)\n",
    "    \n",
    "    # Show\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(f'Original ({original.size[0]}x{original.size[1]})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    if resized is not None:\n",
    "        axes[1].imshow(resized)\n",
    "        axes[1].set_title(f'Resized ({resized.shape[1]}x{resized.shape[0]})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Find a sample image\n",
    "if RAW_DATA_DIR.exists():\n",
    "    sample_images = list(RAW_DATA_DIR.rglob('*.jpg'))[:1]\n",
    "    if sample_images:\n",
    "        show_preprocessing_pipeline(str(sample_images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3eb81",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657958b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_augmentations(image_path: str, n_augmentations: int = 6):\n",
    "    \"\"\"Show data augmentation examples.\"\"\"\n",
    "    # Load and resize image\n",
    "    image = load_and_resize_image(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Could not load image\")\n",
    "        return\n",
    "    \n",
    "    # Get augmentation transforms (without normalization for visualization)\n",
    "    augment = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.3),\n",
    "    ])\n",
    "    \n",
    "    # Generate augmentations\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title('Original', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    for i in range(1, min(n_augmentations + 1, 8)):\n",
    "        augmented = augment(image=image)['image']\n",
    "        axes[i].imshow(augmented)\n",
    "        axes[i].set_title(f'Augmented {i}', fontsize=12)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show augmentation examples\n",
    "if RAW_DATA_DIR.exists():\n",
    "    sample_images = list(RAW_DATA_DIR.rglob('*.jpg'))[:1]\n",
    "    if sample_images:\n",
    "        show_augmentations(str(sample_images[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aeb4f6",
   "metadata": {},
   "source": [
    "## 6. Train/Val/Test Split Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1efbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check processed data splits\n",
    "if PROCESSED_DATA_DIR.exists():\n",
    "    splits = ['train', 'val', 'test']\n",
    "    split_counts = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        split_dir = PROCESSED_DATA_DIR / split\n",
    "        if split_dir.exists():\n",
    "            split_counts[split] = count_images(split_dir)\n",
    "    \n",
    "    # Visualize splits\n",
    "    if split_counts:\n",
    "        classes = list(list(split_counts.values())[0].keys())\n",
    "        x = np.arange(len(classes))\n",
    "        width = 0.25\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        for i, split in enumerate(splits):\n",
    "            if split in split_counts:\n",
    "                counts = [split_counts[split].get(c, 0) for c in classes]\n",
    "                ax.bar(x + i*width, counts, width, label=split.capitalize())\n",
    "        \n",
    "        ax.set_xlabel('Class')\n",
    "        ax.set_ylabel('Number of Images')\n",
    "        ax.set_title('Train/Val/Test Split Distribution')\n",
    "        ax.set_xticks(x + width)\n",
    "        ax.set_xticklabels(classes)\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics\n",
    "        print(\"\\nSplit Statistics:\")\n",
    "        for split in splits:\n",
    "            if split in split_counts:\n",
    "                total = sum(split_counts[split].values())\n",
    "                print(f\"  {split.capitalize()}: {total} images\")\n",
    "else:\n",
    "    print(\"Processed data not found. Run preprocessing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8253f11",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Dataset structure and class distribution\n",
    "2. Sample image visualization\n",
    "3. Image size analysis\n",
    "4. Preprocessing pipeline (resizing to 224x224)\n",
    "5. Data augmentation techniques\n",
    "6. Train/val/test split verification\n",
    "\n",
    "Next steps:\n",
    "- Run `python src/data/preprocess.py` to preprocess the dataset\n",
    "- Train the model with `python src/training/train.py`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
